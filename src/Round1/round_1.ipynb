{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful constants for late access\n",
    "dataset_path = \"P:/Python programs/BNA-2025/src/Round1/dataset\"\n",
    "training_dataset_path = \"P:/Python programs/BNA-2025/src/Round1/dataset/train\"\n",
    "testing_dataset_path = \"P:/Python programs/BNA-2025/src/Round1/dataset/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation:\n",
    "A function to rename all image files in order from 1 onwards so it is more intuitive and easier to recall later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files_in_folder(folder_path):\n",
    "    \"\"\"This function will rename all files in a folder from 1 onwards in the order they are sorted for intuitive ordering.\n",
    "\n",
    "    Args:\n",
    "        folder_path (string): The path to the folder containing the files to be renamed.\n",
    "    \"\"\"\n",
    "    # Get a list of all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    # Sort files to ensure they are renamed in order\n",
    "    files.sort()\n",
    "\n",
    "    # Rename each file\n",
    "    for index, file in enumerate(files, start=1):\n",
    "        # Split the file name and extension\n",
    "        file_name, file_extension = os.path.splitext(file)\n",
    "        \n",
    "        # Generate new file name\n",
    "        new_name = f\"{index}{file_extension}\"\n",
    "        \n",
    "        # Construct full file paths\n",
    "        old_file_path = os.path.join(folder_path, file)\n",
    "        new_file_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(old_file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_files_in_folder(\"\") # add path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulation\n",
    "Multiple functions and call blocks to modify distorted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_color(image_path, destination_path):\n",
    "    \"\"\"\n",
    "    Image inversion is the process of changing the RGB values of a image by subtracting them from the maximum value(255) \n",
    "    for each channel. This will result in the image being 'inverted'\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the inverted image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Image inversion is the process of changing the RGB values of a image by subtracting them from the maximum value(255) for each \n",
    "    # channel. This will result in the image being 'inverted'\n",
    "    from PIL import Image, ImageOps\n",
    "    \n",
    "    # Open the image\n",
    "    inverted_image = Image.open(image_path)\n",
    "    # Invert the image\n",
    "    restored_image = ImageOps.invert(inverted_image)\n",
    "    restored_image.save(destination_path)\n",
    "    \n",
    "def remove_random_noise(image_path, destination_path):\n",
    "    \"\"\"\n",
    "    Removes random noise from an image using a median filter and saves the denoised image to the specified destination.\n",
    "    Random noise refers to black or white pixels that appear on the screen, similar to old school TVs. This noise can occur due to \n",
    "    electromagnetic interference, damaged image sensors, or data corruption. The median filter removes this noise by changing the \n",
    "    value of a distorted pixel to the median value of the pixels around it.\n",
    "    Args:\n",
    "        image_path (str): The file path of the noisy image.\n",
    "        destination_path (str): The file path where the denoised image will be saved.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import numpy as np, cv2\n",
    "\n",
    "    # Open the image with noise\n",
    "    noisy_image = Image.open(image_path)\n",
    "    # Convert to NumPy array\n",
    "    noisy_image_array = np.array(noisy_image)\n",
    "    # Apply median filter to remove noise\n",
    "    denoised_image_array = cv2.medianBlur(noisy_image_array, 3)\n",
    "    # Convert back to PIL image\n",
    "    denoised_image = Image.fromarray(denoised_image_array)\n",
    "    # Save the denoised image\n",
    "    denoised_image.save(destination_path)\n",
    "    \n",
    "def change_brightness(image_path, destination_path, brightness_factor):\n",
    "    \"\"\"\n",
    "    Extreme Brightness levels can either make images too dim making dark parts equal or too bright causing overexposure\n",
    "    and washing out of details. This function will adjust the brightness of an image by a specified factor.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the adjusted image.\n",
    "        brightness_factor (float): A factor by which to adjust the brightness. \n",
    "                                Values > 1.0 increase brightness, \n",
    "                                values < 1.0 decrease brightness.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import ImageEnhance, Image\n",
    "\n",
    "    # Open the distorted image\n",
    "    dim_image = Image.open(image_path)\n",
    "    # Restore brightness\n",
    "    enhancer = ImageEnhance.Brightness(dim_image)\n",
    "    restored_image = enhancer.enhance(brightness_factor)\n",
    "    restored_image.save(destination_path)\n",
    "    \n",
    "def fix_perspective(image_path, destination_path, resolution):\n",
    "    \"\"\"\n",
    "    Corrects the perspective of a skewed image which is image that is stretches in a particular direction. This function will\n",
    "    correct that transformation to make it match the specified resolution and aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): The file path of the skewed image to be corrected.\n",
    "        destination_path (str): The file path where the restored image will be saved.\n",
    "        resolution (tuple, optional): The resolution (width, height) of the restored image. \n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import cv2, numpy as np\n",
    "    \n",
    "    # Read the skewed image\n",
    "    skewed_image = cv2.imread(image_path)\n",
    "    rows, cols, ch = skewed_image.shape\n",
    "    # Define points for reverse perspective transformation\n",
    "    src_points = np.float32([[50, 0], [cols - 50, 0], [0, rows - 1], [cols - 1, rows - 1]])\n",
    "    # Calculate the aspect ratio of the destination resolution\n",
    "    dst_width, dst_height = resolution\n",
    "    dst_points = np.float32([[0, 0], [dst_width - 1, 0], [0, dst_height - 1], [dst_width - 1, dst_height - 1]])\n",
    "    # Apply the reverse perspective warp\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    restored_image = cv2.warpPerspective(skewed_image, matrix, (dst_width, dst_height))\n",
    "\n",
    "    # Save the restored image\n",
    "    cv2.imwrite(destination_path, restored_image)\n",
    "    \n",
    "def crop_image(image_path, destination_path, crop_box):\n",
    "    \"\"\"\n",
    "    Crops an image to a specified box and saves the cropped image to the specified destination.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the cropped image.\n",
    "        crop_box (tuple): A tuple (left, upper, right, lower) defining the box to crop.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Crop the image using the provided box\n",
    "    cropped_image = image.crop(crop_box)\n",
    "    # Save the cropped image\n",
    "    cropped_image.save(destination_path)\n",
    "\n",
    "def resize_image(image_path, destination_path, size):\n",
    "    \"\"\"\n",
    "    Resizes an image to the specified size and saves the resized image to the specified destination.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the resized image.\n",
    "        size (tuple): The desired size as (width, height).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size)\n",
    "    # Save the resized image\n",
    "    resized_image.save(destination_path)\n",
    "\n",
    "def rotate_image(image_path, destination_path, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image by the specified angle and saves the rotated image to the specified destination.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the rotated image.\n",
    "        angle (float): The angle in degrees to rotate the image.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Rotate the image by the specified angle\n",
    "    rotated_image = image.rotate(angle)\n",
    "    # Save the rotated image\n",
    "    rotated_image.save(destination_path)\n",
    "\n",
    "def adjust_contrast(image_path, destination_path, contrast_factor):\n",
    "    \"\"\"\n",
    "    Adjusts the contrast of an image by the specified factor and saves the adjusted image to the specified destination.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the adjusted image.\n",
    "        contrast_factor (float): The factor by which to adjust the contrast. \n",
    "                                 Values > 1.0 increase contrast, values < 1.0 decrease contrast.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import ImageEnhance, Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Enhance the contrast of the image\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    adjusted_image = enhancer.enhance(contrast_factor)\n",
    "    # Save the adjusted image\n",
    "    adjusted_image.save(destination_path)\n",
    "\n",
    "def mirror_image(image_path, destination_path):\n",
    "    \"\"\"\n",
    "    Mirrors an image horizontally and saves the mirrored image to the specified destination.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the mirrored image.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Mirror the image horizontally\n",
    "    mirrored_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    # Save the mirrored image\n",
    "    mirrored_image.save(destination_path)\n",
    "\n",
    "def convert_color_scheme(image_path, destination_path, color_mode):\n",
    "    \"\"\"\n",
    "    Converts the color scheme of an image to the specified mode (e.g., 'RGB', 'L', 'CMYK') and saves the converted image.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The file path to the input image.\n",
    "        destination_path (str): The file path to save the converted image.\n",
    "        color_mode (str): The desired color mode ('RGB', 'L', 'CMYK', etc.).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Convert the image to the specified color mode\n",
    "    converted_image = image.convert(color_mode)\n",
    "    # Save the converted image\n",
    "    converted_image.save(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '' # enter path\n",
    "destination_path = '' # enter path\n",
    "invert_color(img_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'P:/Python programs/BNA-2025/src/Round1/dataset/train/images/IMG_4902.jpg'  # enter path\n",
    "destination_path = 'P:/Python programs/BNA-2025/src/Round1/dataset/'  # enter path\n",
    "remove_random_noise(img_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "brightness_factor = 1.5  # enter desired brightness factor (e.g., 1.5 for brighter)\n",
    "change_brightness(img_path, destination_path, brightness_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "resolution = (800, 600)  # enter desired resolution (width, height)\n",
    "fix_perspective(img_path, destination_path, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "crop_box = (100, 100, 400, 400)  # enter the crop box (left, upper, right, lower)\n",
    "crop_image(img_path, destination_path, crop_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "size = (800, 600)  # enter desired size (width, height)\n",
    "resize_image(img_path, destination_path, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "contrast_factor = 1.5  # enter desired contrast factor (e.g., 1.5 for higher contrast)\n",
    "adjust_contrast(img_path, destination_path, contrast_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "mirror_image(img_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''  # enter path\n",
    "destination_path = ''  # enter path\n",
    "color_mode = 'L'  # enter desired color mode (e.g., 'L' for grayscale, 'RGB' for color)\n",
    "convert_color_scheme(img_path, destination_path, color_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Labelling UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(data_yaml_path):\n",
    "    \"\"\"Load class names from YOLO data.yaml file.\"\"\"\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data['names']\n",
    "\n",
    "def plot_class_distribution(class_names, annotations_path):\n",
    "    \"\"\"Plot class distribution using class names from data.yaml.\"\"\"\n",
    "    class_counts = Counter()\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        class_id = int(line.split()[0])\n",
    "                        class_name = class_names[class_id]\n",
    "                        class_counts[class_name] += 1\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.xlabel('Class Name')\n",
    "    plt.ylabel('Instance Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bounding_box_aspect_ratio(annotations_path):\n",
    "    \"\"\"Plot distribution of bounding box aspect ratios.\"\"\"\n",
    "    aspect_ratios = []\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:  # Ensure the line has enough values\n",
    "                            _, _, w, h = map(float, parts[1:5])\n",
    "                            aspect_ratios.append(w / h)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(aspect_ratios, bins=50, color='salmon', edgecolor='black')\n",
    "    plt.title('Bounding Box Aspect Ratio (Width/Height)')\n",
    "    plt.xlabel('Aspect Ratio')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bounding_box_size(annotations_path):\n",
    "    \"\"\"Plot distribution of bounding box sizes (normalized area).\"\"\"\n",
    "    areas = []\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:  # Ensure the line has enough values\n",
    "                            _, _, w, h = map(float, parts[1:5])\n",
    "                            areas.append(w * h)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(areas, bins=50, color='lightgreen', edgecolor='black')\n",
    "    plt.title('Bounding Box Size (Normalized Area)')\n",
    "    plt.xlabel('Width * Height')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_object_size_vs_image_size(annotations_path, images_path):\n",
    "    \"\"\"Plot object size vs image size (in pixels).\"\"\"\n",
    "    img_areas, obj_areas = [], []\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            # Find corresponding image\n",
    "            img_stem = Path(file_name).stem\n",
    "            img_files = list(Path(images_path).glob(f\"{img_stem}.*\"))\n",
    "            if not img_files:\n",
    "                continue\n",
    "            img = Image.open(img_files[0])\n",
    "            img_w, img_h = img.size\n",
    "            img_area = img_w * img_h\n",
    "            \n",
    "            # Read annotations\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:  # Ensure the line has enough values\n",
    "                            _, _, w_norm, h_norm = map(float, parts[1:5])\n",
    "                            w = w_norm * img_w\n",
    "                            h = h_norm * img_h\n",
    "                            obj_areas.append(w * h)\n",
    "                            img_areas.append(img_area)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(img_areas, obj_areas, alpha=0.3, color='purple')\n",
    "    plt.title('Object Size vs Image Size')\n",
    "    plt.xlabel('Image Area (pixels)')\n",
    "    plt.ylabel('Object Area (pixels)')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_resolution_distribution(annotations_path, images_path):\n",
    "    \"\"\"Plot distribution of image resolutions.\"\"\"\n",
    "    resolutions = []\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            img_stem = Path(file_name).stem\n",
    "            img_files = list(Path(images_path).glob(f\"{img_stem}.*\"))\n",
    "            if img_files:\n",
    "                img = Image.open(img_files[0])\n",
    "                resolutions.append(img.size)\n",
    "\n",
    "    widths, heights = zip(*resolutions) if resolutions else ([], [])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(widths, bins=30, alpha=0.5, label='Width')\n",
    "    plt.hist(heights, bins=30, alpha=0.5, label='Height')\n",
    "    plt.title('Image Resolution Distribution')\n",
    "    plt.xlabel('Pixels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_object_density(annotations_path, grid_size=100):\n",
    "    \"\"\"Plot heatmap of object density across all images.\"\"\"\n",
    "    density = np.zeros((grid_size, grid_size))\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:  # Ensure the line has enough values\n",
    "                            x_center, y_center, _, _ = map(float, parts[1:5])\n",
    "                            x = int(x_center * (grid_size-1))\n",
    "                            y = int(y_center * (grid_size-1))\n",
    "                            density[y, x] += 1\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(density, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar(label='Object Count')\n",
    "    plt.title('Object Density Heatmap')\n",
    "    plt.xlabel('Normalized X')\n",
    "    plt.ylabel('Normalized Y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_aspect_ratio_vs_class(class_names, annotations_path):\n",
    "    \"\"\"Plot aspect ratio distribution per class using class names.\"\"\"\n",
    "    aspect_ratios = {name: [] for name in class_names}\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(annotations_path, file_name), 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:  # Ensure the line has enough values\n",
    "                            class_id = int(parts[0])\n",
    "                            w, h = map(float, parts[3:5])\n",
    "                            aspect_ratio = w / h\n",
    "                            aspect_ratios[class_names[class_id]].append(aspect_ratio)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.violinplot(data=[aspect_ratios[name] for name in class_names])\n",
    "    plt.xticks(ticks=range(len(class_names)), labels=class_names, rotation=45)\n",
    "    plt.title('Aspect Ratio Distribution per Class')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Aspect Ratio (Width/Height)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration paths\n",
    "data_yaml_path = dataset_path + \"/data.yaml\"\n",
    "annotations_path = training_dataset_path + \"/labels\"\n",
    "images_path = training_dataset_path + \"/images\"\n",
    "\n",
    "# Load class names\n",
    "class_names = load_class_names(data_yaml_path)\n",
    "\n",
    "# Generate all plots\n",
    "plot_class_distribution(class_names, annotations_path)\n",
    "plot_bounding_box_aspect_ratio(annotations_path)\n",
    "plot_bounding_box_size(annotations_path)\n",
    "plot_object_size_vs_image_size(annotations_path, images_path)\n",
    "plot_image_resolution_distribution(annotations_path, images_path)\n",
    "plot_object_density(annotations_path)\n",
    "plot_aspect_ratio_vs_class(class_names, annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# set batch=n if memory is not enough\n",
    "! yolo task=detect mode=train model=yolov8n.yaml data='P:/Python programs/BNA-2025/src/Round1/dataset/data.yaml' epochs=30 batch=8 imgsz=640 project=\"C:\\Users\\muahm\\OneDrive\\Desktop\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# add path, model.pt, image source\n",
    "# conf means to show only predictions with confidence greater than n\n",
    "! yolo task=detect mode=predict data=\"\" model=\"\" show=True conf=0.5 source=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = Image.open() # path to confusion matrix\n",
    "results = Image.open() # path to results\n",
    "print(\"Confusion Matrix:\", confusion_matrix)\n",
    "print(\"Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NuemannsMatrixR1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
