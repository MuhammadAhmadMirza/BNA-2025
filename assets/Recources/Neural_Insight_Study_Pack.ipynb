{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Artificial Intelligence**/n",
        "/n",
        "## **What is Artificial Intelligence?**/n",
        "Artificial Intelligence (AI) is the simulation of human intelligence by machines that are programmed to think, learn, and make decisions. AI encompasses a wide range of subfields and techniques, including machine learning, natural language processing, computer vision, and robotics. The ultimate goal of AI is to enable machines to perform tasks that would typically require human intelligence, such as understanding speech, recognizing images, solving problems, and making informed decisions./n",
        "/n",
        "AI can be broadly categorized into three types:/n",
        "1. **Narrow AI**: Specialized systems designed to perform specific tasks (e.g., voice assistants, recommendation systems)./n",
        "2. **General AI**: Hypothetical systems capable of performing any intellectual task that a human can do./n",
        "3. **Super AI**: A future concept of AI that surpasses human intelligence in all fields, including creativity and problem-solving./n",
        "/n",
        "### Applications of AI/n",
        "AI has become an integral part of many industries, driving innovation and efficiency. Some notable applications include:/n",
        "- **Healthcare**: AI is used for diagnosing diseases, personalizing treatment plans, and managing healthcare records./n",
        "- **Finance**: AI helps in fraud detection, algorithmic trading, and credit scoring./n",
        "- **Transportation**: Autonomous vehicles and traffic management systems rely on AI for decision-making./n",
        "- **Retail**: AI enables personalized shopping experiences, inventory management, and dynamic pricing strategies./n",
        "- **Education**: AI powers adaptive learning platforms, virtual tutors, and plagiarism detection tools./n",
        "- **Entertainment**: Recommendation systems for movies, music, and games leverage AI to enhance user engagement./n",
        "- **Agriculture**: AI aids in crop monitoring, pest control, and yield prediction./n",
        "- **Energy**: Smart grids and energy optimization systems utilize AI for efficiency./n",
        "/n",
        "/n",
        "## **Machine Learning**/n",
        "Machine learning (ML) is a subset of AI focused on enabling machines to learn from data and improve performance over time without being explicitly programmed. ML models use algorithms to identify patterns and make predictions or decisions based on input data. These models are trained on datasets and fine-tuned to optimize their performance. ML applications are diverse, ranging from spam email detection to predictive analytics and computer vision./n",
        "/n",
        "ML techniques are generally categorized into three types:/n",
        "1. **Supervised Learning**: The model is trained on labeled data, meaning each input has a corresponding correct output. Examples include image classification and regression problems./n",
        "2. **Unsupervised Learning**: The model identifies patterns and structures in unlabeled data. Examples include clustering and anomaly detection./n",
        "3. **Reinforcement Learning**: The model learns by interacting with its environment and receiving feedback in the form of rewards or penalties. This approach is commonly used in robotics and game-playing AI systems./n",
        "/n",
        "### Deep Learning: A Subset of ML/n",
        "Deep learning is an advanced branch of machine learning inspired by the structure and function of the human brain. It leverages artificial neural networks with many layers (hence the term /"*deep*/") to model complex patterns and relationships in data. Deep learning models have achieved remarkable success in tasks such as image recognition, speech processing, and natural language understanding./n",
        "/n",
        "One of the key advantages of deep learning is its ability to perform **feature extraction** automatically, eliminating the need for manual engineering of features. For example, in image recognition, a deep learning model can autonomously identify edges, textures, and objects within an image. Additionally, deep learning excels in **end-to-end learning**, where the model learns directly from raw input to produce accurate outputs, such as identifying objects in photos or translating languages./n",
        "/n",
        "Deep learning frameworks like TensorFlow and PyTorch provide tools to design and train complex neural networks, enabling researchers and developers to push the boundaries of what AI can achieve. Its applications include self-driving cars, voice assistants, medical diagnostics, and more./n",
        "/n",
        "## **Computer Vision**/n",
        "Computer vision is a field of AI that focuses on enabling machines to interpret and process visual data such as images and videos. By mimicking human visual perception, computer vision allows systems to analyze visual content and make decisions based on it. It is a cornerstone of AI applications, bringing transformative capabilities to industries worldwide./n",
        "/n",
        "Computer vision powers tasks like medical imaging in healthcare, such as detecting tumors from X-rays. In the automotive industry, it enables autonomous vehicles to identify road signs, pedestrians, and obstacles. Other areas include security with facial recognition, automated retail systems, and AR-enhanced gaming./n",
        "/n",
        "Object detection and tracking are among its most critical capabilities. Object detection identifies and locates objects within an image using bounding boxes, while tracking follows these objects across video frames. Together, they underpin real-time applications like self-driving cars, sports analytics, and surveillance systems. Modern algorithms like YOLO (You Only Look Once) have revolutionized this domain, offering high-speed and accurate object detection for dynamic environments."
      ],
      "metadata": {
        "id": "sZmKaLAPaBUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**You Only Look Once (YOLO)**/n",
        "### What is YOLO?/n",
        "YOLO (You Only Look Once) is a state-of-the-art, real-time object detection algorithm that has transformed the way computers identify and locate objects in images and videos. Unlike traditional methods that use a multi-step approach to detect objects, YOLO treats object detection as a single regression problem. It divides the image into a grid and predicts bounding boxes and class probabilities simultaneously for each grid cell, making it exceptionally fast and efficient./n",
        "/n",
        "/n",
        "YOLO models are deep learning models based on convolutional neural networks (CNNs), which excel at extracting hierarchical features from images. These models are trained on large datasets to learn patterns and representations that allow them to identify various objects within an image. By utilizing CNN architectures, YOLO can efficiently process and classify objects in a single pass, significantly speeding up the detection process compared to traditional methods. The model is designed to output both the class label and the precise location of each object in the form of bounding boxes, making it ideal for real-time applications such as autonomous driving, surveillance, and robotics./n",
        "/n",
        "##**Setup**/n",
        "To set up and run a YOLO model, you need to use a Conda Python environment. First, you'll need to install the Anaconda distribution, which is a popular open-source package management system and environment management system for Python and R. Anaconda simplifies package management, dependency resolution, and creating isolated environments, which is especially useful for running complex models like YOLO./n",
        "/n",
        "### Step 1: Install Anaconda/n",
        "You can install Anaconda from the official website:  /n",
        "[Download Anaconda](https://www.anaconda.com/download)/n",
        "> Alternatively follow this URL: https://www.anaconda.com/download/n",
        "/n",
        "### Step 2: Create a Conda Environment/n",
        "Once Anaconda is installed, open the **Anaconda Prompt** (Windows) or a terminal (macOS/Linux) and create a new Conda environment specifically for YOLO. Run the following command to create an environment named `yolo11` (you can choose a different name if desired):/n",
        "/n",
        "```bash/n",
        "  conda create --name yolo11 python=3.8/n",
        "```/n",
        "/n",
        "In this command, `--name yolo11` specifies the environment's name, and `python=3.8` ensures you're using a compatible version of Python for YOLO./n",
        "/n",
        "### Step 3: Activate the Environment/n",
        "To activate the newly created environment, run:/n",
        "/n",
        "```bash/n",
        "  conda activate yolo11/n",
        "```/n",
        "/n",
        "Your terminal will switch to the `yolo11` environment, where you can install the necessary libraries and dependencies for YOLO./n",
        "/n",
        "To deactivate the Conda Environment at any time, simply run the following statement in the **Anaconda Prompt** or terminal/n",
        "```bash/n",
        "  conda deactivate yolo11/n",
        "```/n",
        "This statement will deactivate the `yolo11` environment and return you to your system default environment. Remember, to install any necesaary libraries or dependencies in the `yolo11` Conda environment, the environment must first be activated. This ensures that all installations and changes are applied specifically within the `yolo11` environment./n",
        "### Step 4: Install the Ultralytics YOLO Library/n",
        "Once your Conda environment is activated, the next step is to install the Ultralytics YOLO library. Ultralytics is the developer behind the YOLO models. By installing this library, you gain access to pre-trained YOLO models as well as the ability to train your own models with custom datasets./n",
        "/n",
        "Run the following command to install the Ultralytics package:/n",
        "/n",
        "```bash/n",
        "  pip install ultralytics/n",
        "```/n",
        "This command will install the latest version of the YOLO implementation along with any necessary dependencies."
      ],
      "metadata": {
        "id": "OyyvFIvJhj4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Handling and Image Manipulation**/n",
        "**Data Handling and Image Manipulation** is a crucial aspect of working with computer vision tasks, particularly in training machine learning models like YOLO. It involves the process of efficiently organizing, pre-processing, and augmenting datasets, especially when dealing with large volumes of data. In the context of image manipulation, this includes techniques for correcting data corruption and mitigating image distortions. Image distortions can negatively affect model accuracy, so handling and enhancing image data through methods like resizing, normalizing, or applying filters is essential. Proper data handling ensures that the model is trained on high-quality, relevant data, which is critical for improving performance, robustness, and generalization./n",
        "/n",
        "## **Data Corruption and Image Distortions**/n",
        "/n",
        "Data corruption can occur in various ways, leading to different types of image distortions. These distortions can include issues like noise, blurriness, incorrect color representation, or even missing parts of an image. Such corrupted or distorted data can significantly impact the performance of machine learning models, especially in tasks like object detection or image classification. Fixing corrupted data and correcting image distortions is crucial for ensuring the quality and reliability of the dataset. This process is an essential part of data augmentation and preprocessing, which involves transforming and enhancing data to make it more suitable for training. Effective handling of data corruption and distortions helps improve model accuracy, robustness, and generalization by providing cleaner, more consistent input data, ultimately leading to better model performance./n",
        "/n",
        "### **Color Inversion**/n",
        "/n",
        "Color inversion is a process where the colors in an image are reversed, typically by subtracting each color component from its maximum value. In the case of an 8-bit image, the pixel values for each color channel (red, green, and blue) range from 0 to 255. During color inversion, each pixel's value is subtracted from 255, effectively swapping light and dark colors. For example, a black pixel (0, 0, 0) will become white (255, 255, 255). This can lead to unusual color schemes that may distort the image, making it harder to analyze or recognize patterns, especially in tasks like object detection or image classification. Color inversion can confuse machine learning models by introducing unnecessary noise and disrupting the natural color relationships in the image./n",
        "/n",
        "### Correcting Color Inversion/n",
        "/n",
        "To correct color inversion in an image, you simply need to invert the inversion by subtracting the pixel values from 255 again. Below is a sample Python code using Pillow(PIL) correct color inversion:/n",
        "/n",
        "```python/n",
        "  from PIL import Image, ImageOps/n",
        "/n",
        "  # Open the inverted image/n",
        "  inverted_image = Image.open(/"inverted_image.png/")/n",
        "/n",
        "  # Re-invert to original/n",
        "  restored_image = ImageOps.invert(inverted_image)/n",
        "  restored_image.save(/"restored_image.png/")/n",
        "```/n",
        "/n",
        "By applying this correction, the image's colors are restored to their intended state, improving the dataset quality for machine learning tasks./n",
        "/n",
        "### **Random Noise**/n",
        "Random noise is a type of image distortion where random pixels are set to either the maximum (white) or minimum (black) value, creating scattered black and white spots. This noise can occur due to sensor errors, transmission issues, or other forms of data corruption, and it can significantly impact image quality. In machine learning tasks, especially in object detection or classification, random noise can confuse models by introducing irrelevant information, making it harder for the model to learn meaningful patterns from the image. Removing or reducing random noise is essential to improve dataset quality and model performance./n",
        "/n",
        "### Correcting Random Noise/n",
        "/n",
        "To remove random noise, you can apply a filtering technique, such as a median filter, which helps smooth the image by replacing each pixel value with the median value of the neighboring pixels. Below is a sample Python code using Pillow (PIL) and OpenCV to correct random noise:/n",
        "/n",
        "```python/n",
        "  from PIL import Image/n",
        "  import numpy as np/n",
        "  import cv2/n",
        "/n",
        "  # Open the image with noise/n",
        "  noisy_image = Image.open(/"noisy_image.png/")/n",
        "/n",
        "  # Convert to NumPy array/n",
        "  noisy_image_array = np.array(noisy_image)/n",
        "/n",
        "  # Apply median filter to remove noise/n",
        "  denoised_image_array = cv2.medianBlur(noisy_image_array, 3)/n",
        "/n",
        "  # Convert back to PIL image/n",
        "  denoised_image = Image.fromarray(denoised_image_array)/n",
        "/n",
        "  # Save the denoised image/n",
        "  denoised_image.save(/"denoised_image.png/")/n",
        "```/n",
        "This correction restores the image quality by reducing the noise, making it more suitable for machine learning tasks./n",
        "/n",
        "/n",
        "### **Extreme Brightness Variations**/n",
        "Extreme brightness variations occur when an image's brightness is either excessively reduced or increased, leading to an unnatural appearance. This can happen due to incorrect lighting during image capture or data corruption. For instance, reducing the brightness to 17% of the original image can make it too dark, while increasing it to 165% can cause overexposure, washing out details. These brightness variations can significantly affect image quality, making it difficult for machine learning models to identify key features, recognize objects, or make accurate predictions. Correcting brightness issues is critical for restoring visual consistency and improving model accuracy./n",
        "/n",
        "### Correcting Extreme Brightness Variations/n",
        "To correct extreme brightness variations, you can adjust the image’s brightness by scaling the pixel values to a more appropriate range. Below is a sample Python code using Pillow (PIL) to adjust brightness from 165% to the original image:/n",
        "```python/n",
        "  from PIL import ImageEnhance/n",
        "/n",
        "  # Open the brightened image/n",
        "  dim_image = Image.open(/"dim_image.png/")/n",
        "/n",
        "  # Restore brightness/n",
        "  enhancer = ImageEnhance.Brightness(dim_image)/n",
        "  restored_image = enhancer.enhance(0.606)  # Scale back to original/n",
        "  restored_image.save(/"restored_image.png/")/n",
        "```/n",
        "This correction normalizes the image's brightness, ensuring consistent exposure and making the image more reliable for machine learning tasks./n",
        "/n",
        "/n",
        "### **Warping and Perspective Distortions**/n",
        "Perspective warping and skewing distortions occur when an image is transformed in such a way that its objects appear stretched, compressed, or misaligned. For example, horizontal skewing can cause an image to look stretched sideways, while vertical skewing can make objects appear distorted in the vertical direction. These types of distortions make it difficult for machine learning models to recognize and classify objects correctly, as the relationships between pixels and features are altered. Correcting these distortions is crucial for improving the quality and usability of the image for model training./n",
        "/n",
        "### Correcting Warping and Perspective Distortions/n",
        "To correct perspective and skewing distortions, you can apply geometric transformations like affine transformations or perspective warping. Below is a sample Python code using OpenCV to correct horizontal skewing:/n",
        "```python/n",
        "  import cv2/n",
        "  import numpy as np/n",
        "/n",
        "  # Read the skewed image/n",
        "  skewed_image = cv2.imread(/"skewed_image.png/")/n",
        "  rows, cols, ch = skewed_image.shape/n",
        "/n",
        "  # Define points for reverse perspective transformation/n",
        "  src_points = np.float32([[50, 0], [cols - 50, 0], [0, rows - 1], [cols - 1, rows - 1]])/n",
        "  dst_points = np.float32([[0, 0], [cols - 1, 0], [0, rows - 1], [cols - 1, rows - 1]])/n",
        "/n",
        "  # Apply the reverse perspective warp/n",
        "  matrix = cv2.getPerspectiveTransform(src_points, dst_points)/n",
        "  restored_image = cv2.warpPerspective(skewed_image, matrix, (cols, rows))/n",
        "/n",
        "  # Save the restored image/n",
        "  cv2.imwrite(/"restored_image.png/", restored_image)/n",
        "```/n",
        "This correction restores the image's proper alignment by fixing distortions caused by perspective warping, ensuring the image is more accurate and suitable for machine learning tasks./n",
        "/n",
        "## **Data Labelling and Annotation**/n",
        "/n",
        "Data labeling and annotation are crucial steps in preparing datasets for machine learning models, particularly in the field of computer vision. This process involves marking objects within images with labels and identifying their positions using annotations such as bounding boxes, segmentation masks, or keypoints. In object detection tasks, such as those handled by YOLO (You Only Look Once) models, accurate labeling and annotation enable the models to learn to detect and classify objects within images in real-time./n",
        "/n",
        "For YOLO, each image is annotated with bounding boxes around objects, and each box is labeled with the object's class (e.g., /"car,/" /"person,/" /"dog/"). These annotations serve as ground truth, allowing the model to learn the relationship between pixel patterns and object categories. The quality and accuracy of data labeling and annotation are directly linked to the performance of the model; poor labeling can lead to incorrect predictions and reduced model accuracy. Therefore, careful and precise labeling is essential for building effective computer vision models capable of performing complex tasks such as object detection and classification./n",
        "/n",
        "### **How to Label Data for YOLO Models**/n",
        "To label and annotate data for YOLO (You Only Look Once) models, you need to use specific annotation tools that allow you to create bounding boxes around objects and assign labels to them. A popular choice for this task is **LabelImg**, a graphical image annotation tool that supports YOLO format for creating annotations./n",
        "### Step 1: Install LabelImg/n",
        "LabelImg is an open-source tool and you can install it easily using Conda Python Environemnts. First, activate your specific Conda Environment:/n",
        "```bash/n",
        "  conda activate yolo11/n",
        "```/n",
        "Once the Conda Environment is active, install LabelImg using the following command:/n",
        "```bash/n",
        "  pip install labelimg/n",
        "```/n",
        "This will install the LabelImg package into your active `yolo11` Conda environment, allowing you to use it for annotating images for YOLO object detection./n",
        "### Step 2: Launch LabelImg/n",
        "Once LabelImg is installed, you can launch it by running the following commnad in the active Conda Environment terminal:/n",
        "```bash/n",
        "  labelimg/n",
        "```/n",
        "This will open the LabelImg graphical user interface (GUI) where you can start annotating images./n",
        "### Step 3: Annotate Data Using LabelImg/n",
        "To effectively label and annotate data for YOLO models, follow these resources for detailed guidance and tutorials:/n",
        "/n",
        "- **Official Documentation**: Access the official [LabelImg GitHub page](https://github.com/HumanSignal/labelImg) for installation and usage instructions./n",
        "- **Tutorial Video**: Learn how to use LabelImg through these comprehensive videos:/n",
        "  1. https://www.youtube.com/watch?v=zSda1AoUTkc/n",
        "  2. https://www.youtube.com/watch?v=pTJT8kKi9SM&t=59s/n",
        "  3. https://www.youtube.com/watch?v=v-HIYfOqQeU/n",
        "/n",
        "These resources will guide you through the process of setting up, navigating the GUI, and saving annotations in YOLO format, ensuring your data is properly labeled for training your object detection model./n",
        "/n"
      ],
      "metadata": {
        "id": "-PXvI4fqvqM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**/n",
        "/n",
        "Model training is the process of teaching a machine learning model to make predictions by adjusting its internal parameters (weights) based on labeled data. During training, the model learns patterns in the data to minimize prediction errors, making it capable of generalizing to unseen examples. Training a YOLO model involves feeding it images with annotated objects (ground truth) and optimizing its ability to detect and classify these objects by reducing prediction errors through iterative learning./n",
        "/n",
        "Creating custom YOLO models involves training the model on a specific dataset designed to detect your desired object(s). The process includes preparing labeled images, organizing the dataset into training and validation sets, configuring settings, and either fine-tuning a pre-trained model or training a new model from scratch. This allows the model to specialize in detecting objects unique to your dataset with high precision.  /n",
        "/n",
        "Fine-tuning a pre-trained model uses pre-trained weights and adapts the model to meet your detection goals. This approach leverages knowledge from large-scale datasets, reducing training time. Alternatively, using a configuration file, such as `yolo11n.yaml`, builds a model from scratch. The configuration file specifies the model architecture and is used to train the model exclusively on your dataset’s classes.  /n",
        "/n",
        "In the example file `yolo11n.yaml`, `yolo11` refers to the name and version of the model—YOLO 11 being the latest in the YOLO family. The `n` represents the model scale, which ranges from `n` (nano, smallest scale) to `x` (extra-large, with the most parameters and highest accuracy). The `.yaml` suffix indicates a configuration file, making it essential for defining the model's structure and training parameters. Models built from scratch using `.yaml` files will only detect the classes they are trained on, providing highly specialized detection capabilities./n",
        "/n",
        "## **Train a Custom YOLO Model**/n",
        "To train a Custom YOLO Model, follow these steps:/n",
        "### **Step 1: Dataset Preparation**/n",
        "- **Data Collection**: Collect a diverse set of images that contain the object(s) you wish to detect. Make sure the images cover various conditions such as lighting, angles, and backgrounds./n",
        "- **Data Cleaning**: Remove any irrelevant or poor-quality images that may affect the model’s learning./n",
        "- **Labeling and Pre-processing**: Label the images with bounding boxes around/n",
        "your objects using annotation tools like LabelImg./n",
        "/n",
        "### **Step 2: Organize Dataset**/n",
        "For training a YOLO model, datasets are typically divided into **training** and **validation** sets. The training set is used to teach the model to recognize and learn the objects, while the validation set is used to assess its performance and generalization./n",
        "/n",
        "A common split is **80-20**, where 80% of the dataset is used for training and 20% for validation./n",
        "/n",
        "To organize your dataset, create a root folder called `dataset`. Inside this folder, create two main directories: `train` and `val` for the training and validation sets, respectively. Within each, create subdirectories for **images** and **labels** as follows:/n",
        "```/n",
        "  dataset//n",
        "  ├── train//n",
        "  │   ├── images//n",
        "  │   └── labels//n",
        "  ├── val//n",
        "  │   ├── images//n",
        "  │   └── labels//n",
        "```/n",
        "- `train/images/` and `val/images/`: Store the image files for training and validation, respectively./n",
        "- `train/labels/` and `val/labels/`: Store the corresponding label files in YOLO format for the respective sets./n",
        "/n",
        "This organization ensures a clear and structured dataset for model training and evaluation./n",
        "/n",
        "### **Step 3: Data Configuration**/n",
        "Data configuration involves creating a data.yaml file, which is essential for linking your dataset to the YOLO model during training. This file contains key information such as the paths to your training and validation datasets, the number of classes, and the class names./n",
        "/n",
        "Here’s an improved example of what a data.yaml file might look like:/n",
        "```yaml/n",
        "  train: Users/dataset/train # path directroy to your 'train' folder/n",
        "  val: Users/dataset/images/val # path directroy to your 'val' folder/n",
        "/n",
        "  is_coco: False # if using a dataset like the COCO datset, then set this to True/n",
        "/n",
        "  nc: 5  # Number of classes in dataset/n",
        "  names: ['class1', 'class2', 'class3', 'class4', 'class5'] # list of your class names/n",
        "```/n",
        "This `data.yaml` file helps the YOLO model understand how to access and interpret your dataset during training./n",
        "/n",
        "### **Step 4: Train the Model**/n",
        "To start training your custom YOLO model, follow these steps:/n",
        "/n",
        "### 1. Activate the Conda Python Environment/n",
        "First, activate your Conda environment where the `ultralytics` library and other dependencies are installed. Run the following command in the **Anaconda Prompt** or **terminal**:/n",
        "```bash/n",
        "  conda activate yolo11/n",
        "```/n",
        "/n",
        "### 2. Start the Training Process/n",
        "/n",
        "Once the environment is activated, you can start the training process using the following command:/n",
        "```bash/n",
        "  yolo task=detect mode=train epochs=80 data='path/to/your/data.yaml' model=yolo11n.yaml imgsz=640 batch=8/n",
        "```/n",
        "/n",
        "**Explanation of the command:**/n",
        "- `task=detect`: Specifies that the task is object detection./n",
        "- `mode=train`: Indicates that the model will be trained from scratch or fine-tuned./n",
        "- `epochs=80`: Specifies the number of training epochs (iterations over the dataset)./n",
        "- `data='path/to/your/data.yaml'`: The path to your `data.yaml` file, which contains dataset information./n",
        "- `model=yolo11n.yaml`: Refers to the configuration file for your custom YOLO model. This file defines the model architecture and hyperparameters./n",
        "- `imgsz=640`: Specifies the input image size (640x640 pixels)./n",
        "- `batch=8`: Sets the batch size for training (number of images processed at a time)./n",
        "/n",
        "Alternatively, you can run the training using a Python script in an editor like **VS Code**. Make sure your Conda environment is set as the interpreter for the project. Here's a sample script:/n",
        "/n",
        "```python/n",
        "  import ultralytics/n",
        "  from ultralytics import YOLO/n",
        "/n",
        "  # Load the model configuration (either build from scratch or load a pre-trained model)/n",
        "  model = YOLO(/"yolo11n.yaml/")  # Build a new model from the YAML configuration/n",
        "  # model = YOLO(/"yolo11n.pt/")  # Alternatively, load a pre-trained model/n",
        "/n",
        "  # Train the model/n",
        "  results = model.train(data=/"path/to/your/data.yaml/", epochs=80, imgsz=640)/n",
        "```/n",
        "/n",
        "In this script:/n",
        "- `YOLO(/"yolo11n.yaml/")`: Builds a new model from the configuration file./n",
        "- `YOLO(/"yolo11n.pt/")`: Loads a pre-trained model if you prefer fine-tuning./n",
        "- `results = model.train(...)`: Starts the training with the dataset path and other parameters./n",
        "/n",
        "This method allows you to train your model programmatically and gives you flexibility in managing the training process./n",
        "/n",
        "Once training starts, the model will learn to detect the objects based on the provided dataset, and you can monitor its progress and performance. After the training process is complete, a `runs` directory will be created automatically by the program. This directory contains various subdirectories with evaluation metrics and logs from the validation phase of the training./n",
        "/n",
        "Within this folder, you'll find the `best.pt` file. This file represents the best version of the model based on validation performance across all training epochs. It contains the model's weights, which were learned during the training process, and it can be used for inference or further fine-tuning./n"
      ],
      "metadata": {
        "id": "SqmJWVOSpAAQ"
      }
    }
  ]
}